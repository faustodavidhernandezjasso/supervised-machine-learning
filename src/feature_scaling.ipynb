{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling\n",
    "## What is?\n",
    "It is a technique for increment the performance of gradient descent. \n",
    "Let's start by taking a look at the relationship between the size of a feature\n",
    "and the size of its associated parameter.\n",
    "### Example\n",
    "$$\n",
    "    \\hat{price} = w_{1}x_{1} + w_{2}x_{2} + b\n",
    "$$\n",
    "where:\n",
    "* $x_{1}$: size ($feet^2$) range: 300 - 2000\n",
    "* $x_{2}$: number of bedrooms range: 0 - 5\n",
    "You might notice that when a possible range of values of a feature is large, like the size. It's more likely that a good model will learn to choose a relatively small parameter value. When the possible values of the feature are small, like the number of bedrooms then a reasonable value for its parameters will be relatively large.\n",
    "### How does this relate with gradient descent?\n",
    "Gradient descent may end up bouncing back and forth for a long time before it can finally find its way to the global minimum.\n",
    "**A usefull thing to do is to scale the features**. Doing this will cause that gradient descent can find a much more direct path to the minumum.\n",
    "## How can implement feature scaling?\n",
    "### First way\n",
    "$$\n",
    "    300 \\leq x_{1} \\leq 2000\n",
    "$$\n",
    "then\n",
    "$$\n",
    "    x_{1, scaled} = \\frac{x_{1}}{2000}\n",
    "$$\n",
    "now\n",
    "$$\n",
    "    0.15 \\leq x_{1, scaled} \\leq 1\n",
    "$$\n",
    "### Second way **(Mean normalization)**\n",
    "For each feature $x$ the scaled version is:\n",
    "$$\n",
    "    x = \\frac{x - \\mu}{max - min}\n",
    "$$\n",
    "where $\\mu$ is the avarage of the feature.\n",
    "### Third way **(Z-score normalization)**\n",
    "In this way, we have to use standard deviation $\\sigma$ of the feature and alse we need to use the avarage $\\mu$. Now for each feature $x$ the scaled version of the feature is:\n",
    "$$\n",
    "    x = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking gradient descent for convergence\n",
    "## Make a graph\n",
    "We can use a graph iterations agains $J\\left(\\vec{w}, b\\right)$.\n",
    "## Automatic convergence test \n",
    "Let $\\varepsilon$ be a very small number. If $J\\left(\\vec{w}, b\\right)$ decreases by $\\leq \\varepsilon$ in one iteration declare **convergence**.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
